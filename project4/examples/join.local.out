Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/03/30 17:01:55 INFO SparkContext: Running Spark version 1.5.2
20/03/30 17:01:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/03/30 17:01:56 INFO SecurityManager: Changing view acls to: adp7372
20/03/30 17:01:56 INFO SecurityManager: Changing modify acls to: adp7372
20/03/30 17:01:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(adp7372); users with modify permissions: Set(adp7372)
20/03/30 17:01:56 INFO Slf4jLogger: Slf4jLogger started
20/03/30 17:01:57 INFO Remoting: Starting remoting
20/03/30 17:01:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@198.202.114.159:32977]
20/03/30 17:01:57 INFO Utils: Successfully started service 'sparkDriver' on port 32977.
20/03/30 17:01:57 INFO SparkEnv: Registering MapOutputTracker
20/03/30 17:01:57 INFO SparkEnv: Registering BlockManagerMaster
20/03/30 17:01:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-61d55061-c135-44fe-99a2-e416714b58a4
20/03/30 17:01:57 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
20/03/30 17:01:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-fe378aae-06c1-4434-97da-385ae5209c96/httpd-051d8568-cabd-4180-a4db-9b85ca953fd1
20/03/30 17:01:57 INFO HttpServer: Starting HTTP Server
20/03/30 17:01:57 INFO Utils: Successfully started service 'HTTP file server' on port 45557.
20/03/30 17:01:57 INFO SparkEnv: Registering OutputCommitCoordinator
20/03/30 17:01:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/03/30 17:01:57 INFO SparkUI: Started SparkUI at http://198.202.114.159:4040
20/03/30 17:01:57 INFO SparkContext: Added JAR file:/home/adp7372/project4/examples/join.jar at http://198.202.114.159:45557/jars/join.jar with timestamp 1585612917676
20/03/30 17:01:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
20/03/30 17:01:57 INFO Executor: Starting executor ID driver on host localhost
20/03/30 17:01:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35073.
20/03/30 17:01:57 INFO NettyBlockTransferService: Server created on 35073
20/03/30 17:01:57 INFO BlockManagerMaster: Trying to register BlockManager
20/03/30 17:01:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35073 with 530.0 MB RAM, BlockManagerId(driver, localhost, 35073)
20/03/30 17:01:57 INFO BlockManagerMaster: Registered BlockManager
20/03/30 17:01:58 INFO MemoryStore: ensureFreeSpace(120040) called with curMem=0, maxMem=555755765
20/03/30 17:01:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 117.2 KB, free 529.9 MB)
20/03/30 17:01:58 INFO MemoryStore: ensureFreeSpace(12673) called with curMem=120040, maxMem=555755765
20/03/30 17:01:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.4 KB, free 529.9 MB)
20/03/30 17:01:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35073 (size: 12.4 KB, free: 530.0 MB)
20/03/30 17:01:58 INFO SparkContext: Created broadcast 0 from textFile at JoinSpark.scala:8
20/03/30 17:01:58 INFO MemoryStore: ensureFreeSpace(120080) called with curMem=132713, maxMem=555755765
20/03/30 17:01:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 117.3 KB, free 529.8 MB)
20/03/30 17:01:58 INFO MemoryStore: ensureFreeSpace(12673) called with curMem=252793, maxMem=555755765
20/03/30 17:01:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.4 KB, free 529.8 MB)
20/03/30 17:01:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35073 (size: 12.4 KB, free: 530.0 MB)
20/03/30 17:01:58 INFO SparkContext: Created broadcast 1 from textFile at JoinSpark.scala:10
20/03/30 17:01:58 INFO FileInputFormat: Total input paths to process : 1
20/03/30 17:01:58 INFO FileInputFormat: Total input paths to process : 1
20/03/30 17:01:59 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
20/03/30 17:01:59 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
20/03/30 17:01:59 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
20/03/30 17:01:59 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
20/03/30 17:01:59 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
20/03/30 17:01:59 INFO SparkContext: Starting job: saveAsTextFile at JoinSpark.scala:14
20/03/30 17:01:59 INFO DAGScheduler: Registering RDD 6 (map at JoinSpark.scala:12)
20/03/30 17:01:59 INFO DAGScheduler: Registering RDD 7 (map at JoinSpark.scala:12)
20/03/30 17:01:59 INFO DAGScheduler: Got job 0 (saveAsTextFile at JoinSpark.scala:14) with 3 output partitions
20/03/30 17:01:59 INFO DAGScheduler: Final stage: ResultStage 2(saveAsTextFile at JoinSpark.scala:14)
20/03/30 17:01:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
20/03/30 17:01:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
20/03/30 17:01:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at map at JoinSpark.scala:12), which has no missing parents
20/03/30 17:01:59 INFO MemoryStore: ensureFreeSpace(3688) called with curMem=265466, maxMem=555755765
20/03/30 17:01:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.6 KB, free 529.8 MB)
20/03/30 17:01:59 INFO MemoryStore: ensureFreeSpace(2138) called with curMem=269154, maxMem=555755765
20/03/30 17:01:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.8 MB)
20/03/30 17:01:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35073 (size: 2.1 KB, free: 530.0 MB)
20/03/30 17:01:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
20/03/30 17:01:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at map at JoinSpark.scala:12)
20/03/30 17:01:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
20/03/30 17:01:59 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at JoinSpark.scala:12), which has no missing parents
20/03/30 17:01:59 INFO MemoryStore: ensureFreeSpace(3632) called with curMem=271292, maxMem=555755765
20/03/30 17:01:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 529.7 MB)
20/03/30 17:01:59 INFO MemoryStore: ensureFreeSpace(2094) called with curMem=274924, maxMem=555755765
20/03/30 17:01:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.0 KB, free 529.7 MB)
20/03/30 17:01:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:35073 (size: 2.0 KB, free: 530.0 MB)
20/03/30 17:01:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861
20/03/30 17:01:59 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at JoinSpark.scala:12)
20/03/30 17:01:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2192 bytes)
20/03/30 17:01:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
20/03/30 17:01:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2192 bytes)
20/03/30 17:01:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/03/30 17:01:59 INFO Executor: Fetching http://198.202.114.159:45557/jars/join.jar with timestamp 1585612917676
20/03/30 17:01:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
20/03/30 17:01:59 INFO Utils: Fetching http://198.202.114.159:45557/jars/join.jar to /tmp/spark-fe378aae-06c1-4434-97da-385ae5209c96/userFiles-70a4c822-1eff-4068-96d1-73ea5ce36fde/fetchFileTemp2887772885201877550.tmp
20/03/30 17:01:59 INFO Executor: Adding file:/tmp/spark-fe378aae-06c1-4434-97da-385ae5209c96/userFiles-70a4c822-1eff-4068-96d1-73ea5ce36fde/join.jar to class loader
20/03/30 17:01:59 INFO HadoopRDD: Input split: file:/home/adp7372/project4/examples/e.txt:32+32
20/03/30 17:01:59 INFO HadoopRDD: Input split: file:/home/adp7372/project4/examples/e.txt:0+32
20/03/30 17:01:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2255 bytes result sent to driver
20/03/30 17:01:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2192 bytes)
20/03/30 17:01:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2255 bytes result sent to driver
20/03/30 17:01:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
20/03/30 17:01:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2192 bytes)
20/03/30 17:01:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
20/03/30 17:01:59 INFO HadoopRDD: Input split: file:/home/adp7372/project4/examples/d.txt:0+5
20/03/30 17:01:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 2255 bytes result sent to driver
20/03/30 17:01:59 INFO HadoopRDD: Input split: file:/home/adp7372/project4/examples/d.txt:5+5
20/03/30 17:01:59 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 2255 bytes result sent to driver
20/03/30 17:01:59 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 4, localhost, PROCESS_LOCAL, 2192 bytes)
20/03/30 17:01:59 INFO Executor: Running task 2.0 in stage 1.0 (TID 4)
20/03/30 17:01:59 INFO HadoopRDD: Input split: file:/home/adp7372/project4/examples/d.txt:10+1
20/03/30 17:01:59 INFO Executor: Finished task 2.0 in stage 1.0 (TID 4). 2255 bytes result sent to driver
20/03/30 17:01:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 311 ms on localhost (1/2)
20/03/30 17:01:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 355 ms on localhost (2/2)
20/03/30 17:01:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/03/30 17:01:59 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 4) in 26 ms on localhost (1/3)
20/03/30 17:01:59 INFO DAGScheduler: ShuffleMapStage 0 (map at JoinSpark.scala:12) finished in 0.357 s
20/03/30 17:01:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (2/3)
20/03/30 17:01:59 INFO DAGScheduler: looking for newly runnable stages
20/03/30 17:01:59 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
20/03/30 17:01:59 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/03/30 17:01:59 INFO DAGScheduler: failed: Set()
20/03/30 17:01:59 INFO DAGScheduler: Missing parents for ResultStage 2: List(ShuffleMapStage 1)
20/03/30 17:01:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 67 ms on localhost (3/3)
20/03/30 17:01:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/03/30 17:01:59 INFO DAGScheduler: ShuffleMapStage 1 (map at JoinSpark.scala:12) finished in 0.322 s
20/03/30 17:01:59 INFO DAGScheduler: looking for newly runnable stages
20/03/30 17:01:59 INFO DAGScheduler: running: Set()
20/03/30 17:01:59 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/03/30 17:01:59 INFO DAGScheduler: failed: Set()
20/03/30 17:01:59 INFO DAGScheduler: Missing parents for ResultStage 2: List()
20/03/30 17:01:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at JoinSpark.scala:14), which is now runnable
20/03/30 17:01:59 INFO MemoryStore: ensureFreeSpace(113320) called with curMem=277018, maxMem=555755765
20/03/30 17:01:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 110.7 KB, free 529.6 MB)
20/03/30 17:01:59 INFO MemoryStore: ensureFreeSpace(38024) called with curMem=390338, maxMem=555755765
20/03/30 17:01:59 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.1 KB, free 529.6 MB)
20/03/30 17:01:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:35073 (size: 37.1 KB, free: 529.9 MB)
20/03/30 17:01:59 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861
20/03/30 17:01:59 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at JoinSpark.scala:14)
20/03/30 17:01:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks
20/03/30 17:01:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2026 bytes)
20/03/30 17:01:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, localhost, PROCESS_LOCAL, 2026 bytes)
20/03/30 17:01:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
20/03/30 17:01:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/30 17:01:59 INFO FileOutputCommitter: Saved output of task 'attempt_202003301701_0002_m_000001_6' to file:/home/adp7372/project4/examples/output/_temporary/0/task_202003301701_0002_m_000001
20/03/30 17:01:59 INFO SparkHadoopMapRedUtil: attempt_202003301701_0002_m_000001_6: Committed
20/03/30 17:01:59 INFO FileOutputCommitter: Saved output of task 'attempt_202003301701_0002_m_000000_5' to file:/home/adp7372/project4/examples/output/_temporary/0/task_202003301701_0002_m_000000
20/03/30 17:01:59 INFO SparkHadoopMapRedUtil: attempt_202003301701_0002_m_000000_5: Committed
20/03/30 17:01:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1165 bytes result sent to driver
20/03/30 17:01:59 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, localhost, PROCESS_LOCAL, 2026 bytes)
20/03/30 17:01:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 226 ms on localhost (1/3)
20/03/30 17:01:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1165 bytes result sent to driver
20/03/30 17:01:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 226 ms on localhost (2/3)
20/03/30 17:01:59 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
20/03/30 17:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/30 17:01:59 INFO FileOutputCommitter: Saved output of task 'attempt_202003301701_0002_m_000002_7' to file:/home/adp7372/project4/examples/output/_temporary/0/task_202003301701_0002_m_000002
20/03/30 17:01:59 INFO SparkHadoopMapRedUtil: attempt_202003301701_0002_m_000002_7: Committed
20/03/30 17:01:59 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1165 bytes result sent to driver
20/03/30 17:01:59 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 69 ms on localhost (3/3)
20/03/30 17:01:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/03/30 17:01:59 INFO DAGScheduler: ResultStage 2 (saveAsTextFile at JoinSpark.scala:14) finished in 0.295 s
20/03/30 17:01:59 INFO DAGScheduler: Job 0 finished: saveAsTextFile at JoinSpark.scala:14, took 0.862641 s
20/03/30 17:02:00 INFO SparkUI: Stopped Spark web UI at http://198.202.114.159:4040
20/03/30 17:02:00 INFO DAGScheduler: Stopping DAGScheduler
20/03/30 17:02:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/03/30 17:02:00 INFO MemoryStore: MemoryStore cleared
20/03/30 17:02:00 INFO BlockManager: BlockManager stopped
20/03/30 17:02:00 INFO BlockManagerMaster: BlockManagerMaster stopped
20/03/30 17:02:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/03/30 17:02:00 INFO SparkContext: Successfully stopped SparkContext
20/03/30 17:02:00 INFO ShutdownHookManager: Shutdown hook called
20/03/30 17:02:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe378aae-06c1-4434-97da-385ae5209c96
